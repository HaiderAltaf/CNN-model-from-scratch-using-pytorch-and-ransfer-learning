{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c091e0",
   "metadata": {},
   "source": [
    "# Part-A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b913d",
   "metadata": {},
   "source": [
    "## Question-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb9b45d",
   "metadata": {},
   "source": [
    "Source1- https://blog.paperspace.com/writing-cnns-from-scratch-in-pytorch/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d16aba",
   "metadata": {},
   "source": [
    "source2- https://pyimagesearch.com/2021/07/19/pytorch-training-your-first-convolutional-neural-network-cnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2830da",
   "metadata": {},
   "source": [
    "### load Relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7130a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb87051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU, GELU, SELU, Mish\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0079d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd3d5846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a0f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e5ed706",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2154975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use transforms.compose method to reformat images for modeling,\n",
    "# and save to variable all_transforms for later use, find the size, mean and std for each channel of our dataset\n",
    "def data_pre_processing(batch_size=16, data_augmentation=False):\n",
    "    \n",
    "    all_transforms = transforms.Compose([transforms.Resize((150,150)),\n",
    "                                         transforms.ToTensor(),        #0-255 to 0-1 & numpy to tensor\n",
    "                                         transforms.Normalize(mean=[0.4713, 0.4600, 0.3897],  #0-1 to [-1,1]\n",
    "                                                              std=[0.2373, 0.2266, 0.2374])\n",
    "#                                          transforms.Normalize(mean=[0.5, 0.5, 0.5],  #0-1 to [-1,1]\n",
    "#                                                               std=[0.5, 0.5, 0.5])\n",
    "                                         ])\n",
    "\n",
    "    # path for training and testing dataset directory\n",
    "    train_path = r\"C:\\Users\\HICLIPS-ASK\\nature_12K\\inaturalist_12K\\train\"\n",
    "    test_path = r\"C:\\Users\\HICLIPS-ASK\\nature_12K\\inaturalist_12K\\val\"\n",
    "\n",
    "    train_dataset = torchvision.datasets.ImageFolder(root = train_path, transform = all_transforms)\n",
    "    \n",
    "    # converting train dataset into train and validation for hyperparameter tuning\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    \n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "    \n",
    "    # data augmentation\n",
    "    if data_augmentation == True:\n",
    "        augment_transforms = transforms.Compose([transforms.Resize((150,150)),                                         \n",
    "                                                 transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                                 transforms.RandomRotation((-60,60)),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=[0.4713, 0.4600, 0.3897], \n",
    "                                                              std=[0.2373, 0.2266, 0.2374]),\n",
    "#                                                  transforms.Normalize(mean=[0.5, 0.5, 0.5],  #0-1 to [-1,1]\n",
    "#                                                               std=[0.5, 0.5, 0.5])\n",
    "                                                 \n",
    "                                         ])\n",
    "        \n",
    "        \n",
    "        # uploading train dataset to take a portion and augment it then concate with train dataset\n",
    "        aug_dataset = torchvision.datasets.ImageFolder(root = train_path, transform = augment_transforms)\n",
    "        discrad_size = int(0.8 * len(aug_dataset))\n",
    "        aug_size = len(aug_dataset) - discrad_size\n",
    "        \n",
    "        _ , transformed_dataset = torch.utils.data.random_split(aug_dataset, [discrad_size, aug_size])\n",
    "        train_dataset = torch.utils.data.ConcatDataset([transformed_dataset, train_dataset])\n",
    "\n",
    "    test_dataset = torchvision.datasets.ImageFolder(root = test_path, transform = all_transforms)\n",
    "\n",
    "    # Instantiate loader objects to facilitate processing\n",
    "    # shuffle= True, will ensure data of each class present in each batch\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                               batch_size = batch_size,\n",
    "                                               shuffle = True)\n",
    "\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                               batch_size = batch_size,\n",
    "                                               shuffle = True)\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(dataset = val_dataset,\n",
    "                                               batch_size = batch_size,\n",
    "                                               shuffle = True)\n",
    "    \n",
    "    return train_loader, test_loader, val_loader, train_dataset,test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "315d157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader, val_loader, train_dataset, test_dataset = data_pre_processing(batch_size=64,\n",
    "                                                                                        data_augmentation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cf084b",
   "metadata": {},
   "source": [
    "### Finding the mean and std of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33e46016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataloader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in dataloader:\n",
    "        # Mean over batch, height and width, but not over the channels\n",
    "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum / num_batches\n",
    "\n",
    "    # std = sqrt(E[X^2] - (E[X])^2)\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ba0686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_mean_and_std(train_loader)\n",
    "#[0.4713, 0.4600, 0.3897], [0.2373, 0.2266, 0.2374] for iNaturalist dataset at resize=[150,150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698820c1",
   "metadata": {},
   "source": [
    "### Show image of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "080ba083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(dataset):\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size = 1, shuffle = True)\n",
    "    batch = next(iter(loader))\n",
    "    images, labels = batch\n",
    "    print(images.shape)\n",
    "    \n",
    "    grid = torchvision.utils.make_grid(images, nrow = 3)\n",
    "    plt.figure(figsize= (11,11))\n",
    "    plt.imshow(np.transpose(grid, (1,2,0)))\n",
    "    print('labels', labels)                                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20b29111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_images(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0c06728",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Addition():\n",
    "    def __init__(self, x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def add(self):\n",
    "        return self.x +self.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b85f51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Addition(0,4).add()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f306310d",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f160000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeuNet(Module):\n",
    "    \n",
    "    def __init__(self, size_kernel=4, num_stride=1, act_fu='gelu', size_denseLayer=200,\n",
    "                 data_augmentation=True, batch_normalisation=True, input_channels=3,\n",
    "                 classes=10, padding=1, kernel_org=1, dropout_rate=0.2, num_filters=12):\n",
    "        \n",
    "        # call the parent constructor\n",
    "        super(ConvNeuNet, self).__init__()\n",
    "        \n",
    "        self.batch_norm = batch_normalisation\n",
    "        self.data_aug = data_augmentation\n",
    "        width = 150\n",
    "        height = 150\n",
    "        \n",
    "        #(batch_size = 64, input_channels=3, width=150, height=150)\n",
    "        # initialize first set of CONV => RELU => POOL layers\n",
    "        self.conv1 = Conv2d(in_channels=input_channels, out_channels=num_filters,\n",
    "                    kernel_size=size_kernel, stride=num_stride, padding=padding)\n",
    "        width = int((width- size_kernel + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel + 2*padding)/num_stride) + 1\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=num_filters)\n",
    "        self.af1 = ReLU() if act_fu=='relu' else GELU() if act_fu=='gelu' else SELU() if act_fu=='selu' else Mish()\n",
    "        self.maxpool1 = MaxPool2d(kernel_size=size_kernel, stride=num_stride, padding=padding)\n",
    "        \n",
    "        # updating width and height of the next layer after maxpool\n",
    "        width = int((width- size_kernel + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel + 2*padding)/num_stride) + 1\n",
    "        \n",
    "        # Add dropout layer\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # initialize second set of CONV => RELU => POOL layers\n",
    "        size_kernel = size_kernel*kernel_org\n",
    "        self.conv2 = Conv2d(in_channels=num_filters, out_channels=num_filters,\n",
    "                     kernel_size=size_kernel, stride=num_stride, padding=padding)\n",
    "        width = int((width- size_kernel + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel + 2*padding)/num_stride) + 1\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=num_filters)\n",
    "        self.af2 = ReLU() if act_fu=='relu' else GELU() if act_fu=='gelu' else SELU() if act_fu=='selu' else Mish()\n",
    "        self.maxpool2 = MaxPool2d(kernel_size=size_kernel, stride=num_stride, padding=padding)\n",
    "        \n",
    "        # updating width and height of the next layer after maxpool\n",
    "        width = int((width- size_kernel + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel + 2*padding)/num_stride) + 1\n",
    "        # initialize third set of CONV => RELU => POOL layers\n",
    "        size_kernel = size_kernel*kernel_org\n",
    "        self.conv3 = Conv2d(in_channels=num_filters, out_channels=num_filters,\n",
    "                     kernel_size=size_kernel, stride=num_stride, padding=padding)\n",
    "        width = int((width- size_kernel + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel + 2*padding)/num_stride) + 1\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=num_filters)\n",
    "        self.af3 = ReLU() if act_fu=='relu' else GELU() if act_fu=='gelu' else SELU() if act_fu=='selu' else Mish()\n",
    "        self.maxpool3 = MaxPool2d(kernel_size=size_kernel, stride=num_stride, padding=padding)\n",
    "        \n",
    "         # updating width and height of the next layer after maxpool\n",
    "        width = int((width- size_kernel + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel + 2*padding)/num_stride) + 1\n",
    "        # initialize fourth set of CONV => RELU => POOL layers\n",
    "        size_kernel = size_kernel*kernel_org\n",
    "        self.conv4 = Conv2d(in_channels=num_filters, out_channels=num_filters,\n",
    "                     kernel_size=size_kernel, stride=num_stride, padding=padding)\n",
    "        width = int((width- size_kernel + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel + 2*padding)/num_stride) + 1\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=num_filters)\n",
    "        self.af4 = ReLU() if act_fu=='relu' else GELU() if act_fu=='gelu' else SELU() if act_fu=='selu' else Mish()\n",
    "        self.maxpool4 = MaxPool2d(kernel_size=size_kernel, stride=num_stride, padding=padding)\n",
    "        \n",
    "        # updating width and height of the next layer after maxpool\n",
    "        width = int((width- size_kernel + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel + 2*padding)/num_stride) + 1\n",
    "        # initialize fifth set of CONV => RELU => POOL layers\n",
    "        size_kernel = size_kernel*kernel_org\n",
    "        self.conv5 = Conv2d(in_channels=num_filters, out_channels=num_filters,\n",
    "                     kernel_size=size_kernel, stride=num_stride, padding=padding)\n",
    "        width = int((width- size_kernel + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel + 2*padding)/num_stride) + 1\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=num_filters)\n",
    "        self.af5 = ReLU() if act_fu=='relu' else GELU() if act_fu=='gelu' else SELU() if act_fu=='selu' else Mish()\n",
    "        self.maxpool5 = MaxPool2d(kernel_size=size_kernel, stride=num_stride, padding=padding)\n",
    "        \n",
    "        # updating width and height of the next layer after maxpool\n",
    "        width = int((width- size_kernel + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel + 2*padding)/num_stride) + 1\n",
    "        #initialize first (and only) set of FC => RELU layers\n",
    "        self.fc1 = Linear(in_features=int(num_filters*width*height), out_features=size_denseLayer)\n",
    "        self.af6 = ReLU() if act_fu=='relu' else GELU() if act_fu=='gelu' else SELU() if act_fu=='selu' else Mish()\n",
    "        \n",
    "        # initialize our softmax classifier\n",
    "        self.fc2 = Linear(in_features=size_denseLayer, out_features=classes)\n",
    "        self.logSoftmax = LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # pass the input through our first set of CONV => Batch_norm => RELU =>\n",
    "        # POOL layers\n",
    "        x = self.conv1(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn1(x)\n",
    "        x = self.af1(x)\n",
    "        x = self.maxpool1(x)\n",
    "       \n",
    "        # pass the output from the previous layer through the second\n",
    "        # set of CONV => Batch_norm => RELU => layers\n",
    "        x = self.conv2(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn2(x)\n",
    "        x = self.af2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        # pass the output from the previous layer through the third\n",
    "        # set of CONV => Batch_norm => RELU => POOL layers\n",
    "        x = self.conv3(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn3(x)\n",
    "        x = self.af3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        # pass the output from the previous layer through the fourth\n",
    "        # set of CONV => Batch_norm => RELU => POOL layers\n",
    "        x = self.conv4(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn4(x)\n",
    "        x = self.af4(x)\n",
    "        x = self.maxpool4(x)\n",
    "        # pass the output from the previous layer through the fifth\n",
    "        # set of CONV => Batch_norm => RELU => POOL layers\n",
    "        x = self.conv5(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn5(x)\n",
    "        x = self.af5(x)\n",
    "        x = self.maxpool5(x)\n",
    "        # flatten the output from the previous layer and pass it\n",
    "        # through our only set of FC => RELU layers\n",
    "        x = flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.af6(x)\n",
    "        # pass the output to our softmax classifier to get our output\n",
    "        # predictions\n",
    "        x = self.fc2(x)\n",
    "        output = self.logSoftmax(x)\n",
    "        # return the output predictions\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd524537",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNeuNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93e55f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer and loss function\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.0001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1da2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f626818d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0Train Loss: 2Train Accuracy: 0Test Accuracy: 0\n"
     ]
    }
   ],
   "source": [
    "#Model training and saving best model\n",
    "\n",
    "best_accuracy=0.0\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluating and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        #print(images.shape())\n",
    "        if torch.cuda.is_available():\n",
    "            images=images.cuda()\n",
    "            labels=labels.cuda()\n",
    "        \n",
    "        # make grad to zero after each batch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/len(train_dataset)\n",
    "    train_loss=train_loss/len(train_dataset)\n",
    "        \n",
    "    \n",
    "    #Evaluating on validation dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=images.cuda()\n",
    "            labels=labels.cuda()\n",
    "            \n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    test_accuracy=test_accuracy/len(test_dataset)\n",
    "    \n",
    "    print(\"Epoch: \"+str(epoch)+ 'Train Loss: '+str(int(train_loss))+'Train Accuracy: '+\n",
    "          str(int(train_accuracy))+ 'Test Accuracy: '+str(int(test_accuracy)))  \n",
    "    \n",
    "    \n",
    "    # save the best model\n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e459c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a6ed27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
