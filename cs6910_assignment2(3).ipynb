{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c091e0",
   "metadata": {},
   "source": [
    "# Part-A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b913d",
   "metadata": {},
   "source": [
    "## Question-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb9b45d",
   "metadata": {},
   "source": [
    "Source1- https://blog.paperspace.com/writing-cnns-from-scratch-in-pytorch/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d16aba",
   "metadata": {},
   "source": [
    "source2- https://pyimagesearch.com/2021/07/19/pytorch-training-your-first-convolutional-neural-network-cnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2830da",
   "metadata": {},
   "source": [
    "### load Relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7130a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb87051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU, GELU, SELU, Mish\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0079d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d92d5c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0ea62",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2154975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use transforms.compose method to reformat images for modeling,\n",
    "# and save to variable all_transforms for later use, find the size, mean and std for each channel of our dataset\n",
    "def data_pre_processing(batch_size=16, data_augmentation=False):\n",
    "    \n",
    "    all_transforms = transforms.Compose([transforms.Resize((150,150)),\n",
    "                                         transforms.ToTensor(),        #0-255 to 0-1 & numpy to tensor\n",
    "                                         transforms.Normalize(mean=[0.4713, 0.4600, 0.3897],  #0-1 to [-1,1]\n",
    "                                                              std=[0.2373, 0.2266, 0.2374])                                        \n",
    "                                         ])\n",
    "\n",
    "    # path for training and testing dataset directory\n",
    "    train_path = r\"C:\\Users\\HICLIPS-ASK\\nature_12K\\inaturalist_12K\\train\"\n",
    "    test_path = r\"C:\\Users\\HICLIPS-ASK\\nature_12K\\inaturalist_12K\\val\"\n",
    "\n",
    "    train_dataset = torchvision.datasets.ImageFolder(root = train_path, transform = all_transforms)\n",
    "    \n",
    "    # converting train dataset into train and validation for hyperparameter tuning\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    \n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "    \n",
    "    # data augmentation\n",
    "    if data_augmentation == True:\n",
    "        augment_transforms = transforms.Compose([transforms.Resize((150,150)),                                         \n",
    "                                                 transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                                 transforms.RandomRotation((-60,60)),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=[0.4713, 0.4600, 0.3897], \n",
    "                                                              std=[0.2373, 0.2266, 0.2374])\n",
    "                                                 \n",
    "                                         ])\n",
    "        \n",
    "        \n",
    "        # uploading train dataset to take a portion and augment it then concate with train dataset\n",
    "        aug_dataset = torchvision.datasets.ImageFolder(root = train_path, transform = augment_transforms)\n",
    "        discrad_size = int(0.8 * len(aug_dataset))\n",
    "        aug_size = len(aug_dataset) - discrad_size\n",
    "        \n",
    "        _ , transformed_dataset = torch.utils.data.random_split(aug_dataset, [discrad_size, aug_size])\n",
    "        train_dataset = torch.utils.data.ConcatDataset([transformed_dataset, train_dataset])\n",
    "\n",
    "    test_dataset = torchvision.datasets.ImageFolder(root = test_path, transform = all_transforms)\n",
    "\n",
    "    # Instantiate loader objects to facilitate processing\n",
    "    # shuffle= True, will ensure data of each class present in each batch\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                               batch_size = batch_size,\n",
    "                                               shuffle = True)\n",
    "\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                               batch_size = batch_size,\n",
    "                                               shuffle = True)\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(dataset = val_dataset,\n",
    "                                               batch_size = batch_size,\n",
    "                                               shuffle = True)\n",
    "    \n",
    "    return train_loader, test_loader, val_loader, train_dataset,test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e521269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader, val_loader, train_dataset, test_dataset = data_pre_processing(batch_size=64,\n",
    "                                                                                        data_augmentation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14660e8",
   "metadata": {},
   "source": [
    "### Finding the mean and std of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330681fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataloader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in dataloader:\n",
    "        # Mean over batch, height and width, but not over the channels\n",
    "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum / num_batches\n",
    "\n",
    "    # std = sqrt(E[X^2] - (E[X])^2)\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b4e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_mean_and_std(train_loader)\n",
    "#[0.4713, 0.4600, 0.3897], [0.2373, 0.2266, 0.2374] for iNaturalist dataset at resize=[150,150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ae2704",
   "metadata": {},
   "source": [
    "### Show image of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8528a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(dataset):\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size = 1, shuffle = True)\n",
    "    batch = next(iter(loader))\n",
    "    images, labels = batch\n",
    "    print(images.shape)\n",
    "    \n",
    "    grid = torchvision.utils.make_grid(images, nrow = 3)\n",
    "    plt.figure(figsize= (11,11))\n",
    "    plt.imshow(np.transpose(grid, (1,2,0)))\n",
    "    print('labels', labels)                                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_images(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b640c05",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f160000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeuNet(Module):\n",
    "    \n",
    "    def __init__(self, size_kernel=[(3,3),(3,3),(3,3),(3,3),(3,3)], num_stride=1, act_fu='selu', size_denseLayer=200,\n",
    "                 data_augmentation=True, batch_normalisation=True, input_channels=3,\n",
    "                 classes=10, padding=1, kernel_org=0.5, dropout_rate=0.2, num_filters=[16,16,16,16,16]):\n",
    "        \n",
    "        # call the parent constructor\n",
    "        super(ConvNeuNet, self).__init__()\n",
    "        \n",
    "        self.batch_norm = batch_normalisation\n",
    "        self.data_aug = data_augmentation\n",
    "        width = 150\n",
    "        height = 150\n",
    "        \n",
    "        #(batch_size = 64, input_channels=3, width=150, height=150)\n",
    "        # initialize first set of CONV => RELU => POOL layers\n",
    "        self.conv1 = Conv2d(in_channels=input_channels, out_channels=num_filters[0],\n",
    "                    kernel_size=size_kernel[0], stride=num_stride, padding=padding)\n",
    "        width = int((width- size_kernel[0][0] + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel[0][0] + 2*padding)/num_stride) + 1\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=num_filters[0])\n",
    "        self.af1 = ReLU() if act_fu=='relu' else GELU() if act_fu=='gelu' else SELU() if act_fu=='selu' else Mish()\n",
    "        self.dropout1 = nn.Dropout(p=dropout_rate)\n",
    "        self.maxpool1 = MaxPool2d(kernel_size=size_kernel[0], stride=num_stride, padding=padding)\n",
    "        \n",
    "        # updating width and height of the next layer after maxpool\n",
    "        width = int((width- size_kernel[0][0] + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel[0][0] + 2*padding)/num_stride) + 1\n",
    "        \n",
    "        # initialize second set of CONV => RELU => POOL layers\n",
    "        \n",
    "        self.conv2 = Conv2d(in_channels=num_filters[0], out_channels=num_filters[1],\n",
    "                     kernel_size=size_kernel[1], stride=num_stride, padding=padding)\n",
    "        width = int((width- size_kernel[1][0] + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel[1][0] + 2*padding)/num_stride) + 1\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=num_filters[1])\n",
    "        self.af2 = ReLU() if act_fu=='relu' else GELU() if act_fu=='gelu' else SELU() if act_fu=='selu' else Mish()\n",
    "        self.dropout2 = nn.Dropout(p=dropout_rate)\n",
    "        self.maxpool2 = MaxPool2d(kernel_size=size_kernel[1], stride=num_stride, padding=padding)\n",
    "        \n",
    "        # updating width and height of the next layer after maxpool\n",
    "        width = int((width- size_kernel[1][0] + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel[1][0] + 2*padding)/num_stride) + 1\n",
    "        \n",
    "        # initialize third set of CONV => RELU => POOL layers\n",
    "        self.conv3 = Conv2d(in_channels=num_filters[1], out_channels=num_filters[2],\n",
    "                     kernel_size=size_kernel[2], stride=num_stride, padding=padding)\n",
    "        width = int((width- size_kernel[2][0] + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel[2][0] + 2*padding)/num_stride) + 1\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=num_filters[2])\n",
    "        self.af3 = ReLU() if act_fu=='relu' else GELU() if act_fu=='gelu' else SELU() if act_fu=='selu' else Mish()\n",
    "        self.dropout3 = nn.Dropout(p=dropout_rate)\n",
    "        self.maxpool3 = MaxPool2d(kernel_size=size_kernel[2], stride=num_stride, padding=padding)\n",
    "        \n",
    "         # updating width and height of the next layer after maxpool\n",
    "        width = int((width- size_kernel[2][0] + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel[2][0] + 2*padding)/num_stride) + 1\n",
    "        \n",
    "        # initialize fourth set of CONV => RELU => POOL layers\n",
    "        self.conv4 = Conv2d(in_channels=num_filters[2], out_channels=num_filters[3],\n",
    "                     kernel_size=size_kernel[3], stride=num_stride, padding=padding)\n",
    "        width = int((width- size_kernel[3][0] + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel[3][0] + 2*padding)/num_stride) + 1\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=num_filters[3])\n",
    "        self.af4 = ReLU() if act_fu=='relu' else GELU() if act_fu=='gelu' else SELU() if act_fu=='selu' else Mish()\n",
    "        self.dropout4 = nn.Dropout(p=dropout_rate)\n",
    "        self.maxpool4 = MaxPool2d(kernel_size=size_kernel[3], stride=num_stride, padding=padding)\n",
    "        \n",
    "        # updating width and height of the next layer after maxpool\n",
    "        width = int((width- size_kernel[3][0] + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel[3][0] + 2*padding)/num_stride) + 1\n",
    "        \n",
    "        # initialize fifth set of CONV => RELU => POOL layers\n",
    "        self.conv5 = Conv2d(in_channels=num_filters[3], out_channels=num_filters[4],\n",
    "                     kernel_size=size_kernel[4], stride=num_stride, padding=padding)\n",
    "        width = int((width- size_kernel[4][0] + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel[4][0] + 2*padding)/num_stride) + 1\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=num_filters[4])\n",
    "        self.af5 = ReLU() if act_fu=='relu' else GELU() if act_fu=='gelu' else SELU() if act_fu=='selu' else Mish()\n",
    "        self.dropout5 = nn.Dropout(p=dropout_rate)\n",
    "        self.maxpool5 = MaxPool2d(kernel_size=size_kernel[4], stride=num_stride, padding=padding)\n",
    "        \n",
    "        # updating width and height of the next layer after maxpool\n",
    "        width = int((width- size_kernel[4][0] + 2*padding)/num_stride) + 1\n",
    "        height = int((height- size_kernel[4][0] + 2*padding)/num_stride) + 1\n",
    "        #initialize first (and only) set of FC => RELU layers\n",
    "        self.fc1 = Linear(in_features=int(num_filters[4]*width*height), out_features=size_denseLayer)\n",
    "        self.af6 = ReLU() if act_fu=='relu' else GELU() if act_fu=='gelu' else SELU() if act_fu=='selu' else Mish()\n",
    "        self.dropout6 = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        # initialize our softmax classifier\n",
    "        self.fc2 = Linear(in_features=size_denseLayer, out_features=classes)\n",
    "        self.logSoftmax = LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # pass the input through our first set of CONV => Batch_norm => RELU =>\n",
    "        # POOL layers\n",
    "        x = self.conv1(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn1(x)\n",
    "        x = self.af1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.maxpool1(x)\n",
    "       \n",
    "        # pass the output from the previous layer through the second\n",
    "        # set of CONV => Batch_norm => RELU => layers\n",
    "        x = self.conv2(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn2(x)\n",
    "        x = self.af2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        # pass the output from the previous layer through the third\n",
    "        # set of CONV => Batch_norm => RELU => POOL layers\n",
    "        x = self.conv3(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn3(x)\n",
    "        x = self.af3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        # pass the output from the previous layer through the fourth\n",
    "        # set of CONV => Batch_norm => RELU => POOL layers\n",
    "        x = self.conv4(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn4(x)\n",
    "        x = self.af4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.maxpool4(x)\n",
    "        # pass the output from the previous layer through the fifth\n",
    "        # set of CONV => Batch_norm => RELU => POOL layers\n",
    "        x = self.conv5(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn5(x)\n",
    "        x = self.af5(x)\n",
    "        x = self.dropout5(x)\n",
    "        x = self.maxpool5(x)\n",
    "        # flatten the output from the previous layer and pass it\n",
    "        # through our only set of FC => RELU layers\n",
    "        x = flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.af6(x)\n",
    "        x = self.dropout6(x)\n",
    "        # pass the output to our softmax classifier to get our output\n",
    "        # predictions\n",
    "        x = self.fc2(x)\n",
    "        output = self.logSoftmax(x)\n",
    "        # return the output predictions\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67e5302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNeuNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "240dc13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer and loss function\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.0001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55aa3c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9ae0573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation function\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37493ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb\n",
    "# import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1550eb5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model training and saving best model\n",
    "\n",
    "def train_CNN():\n",
    "    \n",
    "\n",
    "#     # default values\n",
    "#     config_defaults = {\n",
    "#         'num_filters': [16,16,16,16,16],\n",
    "#         'act_fu': 'selu',\n",
    "#         'size_kernel': [(3,3),(3,3),(3,3),(3,3),(3,3)],\n",
    "#         'data_augmentation': True,\n",
    "#         'batch_normalisation': True,\n",
    "#         'dropout_rate': 0.2\n",
    "#          }\n",
    "    \n",
    "#     #loading the dataloaders and dataset\n",
    "#     train_loader, test_loader, val_loader, train_dataset, test_dataset = data_pre_processing(batch_size=64,\n",
    "#                                                                                         data_augmentation=True)\n",
    "\n",
    "#     # initialize wandb\n",
    "#     wandb.init(config=config_defaults)\n",
    "\n",
    "#     # config is a data structure that holds hyperparameters and inputs\n",
    "#     config = wandb.config\n",
    "\n",
    "#     # Local variables, values obtained from wandb config\n",
    "#     num_filters = config.num_filters\n",
    "#     act_fu = config.act_fu\n",
    "#     size_kernel = config.size_kernel\n",
    "#     data_augmentation = config.data_augmentation\n",
    "#     batch_normalisation = config.batch_normalisation\n",
    "#     dropout_rate = config.dropout_rate\n",
    "\n",
    "#     wandb.run.name  = \"filSize_{}_af_{}_NF_{}_DA_{}_BN_{}_Drp_{}\".format(size_kernel,\n",
    "#                                                                           act_fu,\n",
    "#                                                                           num_filters,\n",
    "#                                                                           data_augmentation,\n",
    "#                                                                           batch_normalisation,\n",
    "#                                                                           dropout_rate)\n",
    "                                                                             \n",
    "\n",
    "\n",
    "\n",
    "#     print(wandb.run.name )\n",
    "\n",
    "    best_accuracy=0.0    \n",
    "    # Training on training dataset\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                train_loss=running_loss/100   \n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Evaluate training set accuracy\n",
    "        train_accuracy = evaluate(model, train_loader)\n",
    "\n",
    "        # Evaluate test set accuracy\n",
    "        val_accuracy = evaluate(model, val_loader)\n",
    "\n",
    "\n",
    "        print(\"Epoch: \"+str(epoch+1)+ ' Train Loss:'+ str(train_loss) +' Train Accuracy:'+\n",
    "              str(train_accuracy) + ' Validation Accuracy: '+ str(val_accuracy)) \n",
    "\n",
    "\n",
    "        # save the best model\n",
    "        if val_accuracy>best_accuracy:\n",
    "            torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "            best_accuracy=val_accuracy\n",
    "            \n",
    "#         wandb.log({\"validation accuracy\": val_accuracy, \"train accuracy\": train_accuracy, \n",
    "#                     \"train loss\": train_loss, 'epoch': epoch+1})\n",
    "    \n",
    "#         wandb.run.name \n",
    "#         wandb.run.save()\n",
    "#         wandb.run.finish()\n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a052d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss:2.922202019691467 Train Accuracy:14.40180022502813 Validation Accuracy: 12.95\n",
      "Epoch: 2 Train Loss:2.238641633987427 Train Accuracy:19.839979997499686 Validation Accuracy: 18.2\n",
      "Epoch: 3 Train Loss:2.1790716528892515 Train Accuracy:23.990498812351543 Validation Accuracy: 22.2\n"
     ]
    }
   ],
   "source": [
    "train_CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d795d88",
   "metadata": {},
   "source": [
    "# Running the wandb sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3414c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\"name\": \"cs6910_assignment2\", \"method\": \"bayes\"}   \n",
    "sweep_config[\"metric\"] = {\"name\": \"val_accuracy\", \"goal\": \"maximize\"}\n",
    "\n",
    "parameters_dict = {\n",
    "              \"num_filters\": {\"values\": [[16,16,16,16,16],[4,8,16,32,64],[64,32,16,8,4]]},\n",
    "              \"act_fu\": {\"values\": [\"gelu\",\"selu\",\"mish\"]},\n",
    "              \"size_kernel\": {\"values\": [[(3,3),(3,3),(3,3),(3,3),(3,3)], [(3,3),(5,5),(5,5),(7,7),(7,7)], \n",
    "                                         [(7,7),(7,7),(5,5),(5,5),(3,3)]]}, \n",
    "                \"data_augmentation\": {\"values\": [True, False]} ,\n",
    "                \"batch_normalisation\": {\"values\": [True, False]} ,\n",
    "                \"dropout_rate\": {\"values\": [0.2, 0.3]}, \n",
    "                }\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, entity=\"am22s020\", project=\"cs6910_assignment2\")\n",
    "wandb.agent(sweep_id, train_CNN, count=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
